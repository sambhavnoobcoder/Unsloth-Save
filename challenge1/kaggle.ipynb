{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# UNSLOTH CHALLENGE 1 SUBMISSION : Convert nf4 to Triton.","metadata":{}},{"cell_type":"markdown","source":"## Problem statement","metadata":{}},{"cell_type":"markdown","source":"---\n---\n---\n<a name=\"NF4\"></a>\n## A) Convert `nf4` to Triton. [Difficulty: Hard] [Max points: 14]\n\n1. Goal: Convert a `nf4` quantized tensor into `fp16` or `bf16` into a *single* Triton kernel The double dequant of the `absmax` and weight forming must be done in 1 Triton kernel. Must work on Tesla T4.\n2. Must be faster than Unsloth's `fast_dequantize` by 1.15x or more, and not use large intermediate memory buffers.\n3. Must not use `torch.compile`, but can use `trace.enabled` to help on writing Triton kernels.\n4. Good material: [Unsloth `fast_dequantize` function](https://github.com/unslothai/unsloth/blob/main/unsloth/kernels/utils.py#L128), also [bitsandbytes `dequantize_blockwise`](https://github.com/bitsandbytes-foundation/bitsandbytes/blob/86b6c37a8ad448230cedb60753f63150b603a112/bitsandbytes/functional.py#L958)\n5. Use `test_dequantize_function` to test your implementation.\n6. No CUDA allowed. Custom CUDA inside of the Triton is allowed.\n7. Watch Tim's videos on Youtube: [8-bit Optimizers](https://www.youtube.com/watch?v=2ETNONas068)","metadata":{}},{"cell_type":"markdown","source":"## Evaluation parameters ","metadata":{}},{"cell_type":"markdown","source":"## Marking Criteria for A) Max points = 14\n```python\nif attemped_A:\n    A_score = 0\n    if single_triton_kernel: A_score += 3\n    speedup = old_time / new_time\n    if speedup <= 1.00: A_score -= 3\n    if speedup >= 1.05: A_score += 1\n    if speedup >= 1.10: A_score += 2\n    if speedup >= 1.15: A_score += 2\n    if kernel_works_in_torch_compile: A_score += 1\n    else: A_score -= 1\n    if custom_asm_works: A_score += 3\n    if uses_cache_eviction: A_score += 1\n    if tested_in_f16_and_bf16: A_score += 1\n    else: A_score -= 1\n    final_score += A_score\nelse:\n    final_score += 0\n```","metadata":{}},{"cell_type":"markdown","source":"lets load up the basic libraries","metadata":{}},{"cell_type":"code","source":"!pip install triton","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}