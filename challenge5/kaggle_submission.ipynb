{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c524a9",
   "metadata": {
    "papermill": {
     "duration": 0.003898,
     "end_time": "2025-03-17T11:12:50.854072",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.850174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UNSLOTH CHALLENGE 5 SUBMISSION - Memory Efficient Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902366e7",
   "metadata": {
    "papermill": {
     "duration": 0.002868,
     "end_time": "2025-03-17T11:12:50.860434",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.857566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a73a2",
   "metadata": {
    "papermill": {
     "duration": 0.002824,
     "end_time": "2025-03-17T11:12:50.866476",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.863652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "<a name=\"MATH\"></a>\n",
    "## E) Memory Efficient Backprop [Difficulty: Medium to Hard] [Max points: 10]\n",
    "\n",
    "In LLMs, the last layer is a projection matrix to calculate the probabilities of the next token, ie $\\sigma(XW)$. However, if the vocabulary size is very large, say 128K, then the materialization of the logits causes VRAM spikes.\n",
    "\n",
    "For example, if the `bsz = 4, qlen = 4096, hd = 4096, vocab = 128K`, then the memory usage for the logits in bfloat16 would be 4GB. In the worst case, we might even need to upcast logits to float32, so 8GB is needed.\n",
    "\n",
    "In Unsloth, we utilize [Apple's Cut Cross Entropy Loss](https://machinelearning.apple.com/research/cut-your-losses) to reduce VRAM usage, by allowing a Triton kernel to create the logits on the fly to calculate the cross entropy loss. But this does not generalize well to other functions.\n",
    "\n",
    "Our goal is to generalize this ultimately, but directly creating logits on the fly will be hard. Instead, let's take a slightly less complex approach. Let's first review some stuff. We first notice that during the normal case after forming the intermediate logits for 2 batches, we then do a gather function to aggregate the intermediate results into a single column:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\times W &= \\begin{bmatrix} x_1 W \\\\ x_2 W \\end{bmatrix} \\\\\n",
    "f \\bigg( \\begin{bmatrix} x_1 W \\\\ x_2 W \\end{bmatrix} \\bigg) &= \\begin{pmatrix} y_1 \\\\ y_2 \\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So, if we can somehow skip the materialization of the intermediate logits, and just output the output of `f`, we can save a lot of VRAM!\n",
    "\n",
    "Notice during backpropagation we can use the chain rule:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dL}{dX} &= \\frac{dL}{dy} \\frac{dy}{dX} ; \\frac{dL}{dW} = \\frac{dL}{dy} \\frac{dy}{dW} \\\\\n",
    "\\frac{dL}{dy} &= \\text{Downstream from backprop} \\\\\n",
    "\\frac{dy}{dX} &= W^T \\\\\n",
    "\\frac{dy}{dW} &= X^T \\\\\n",
    "\\frac{dL}{dX} &= \\frac{dL}{dy} W^T \\\\\n",
    "\\frac{dL}{dW} &= X^T \\frac{dL}{dy} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we simply compute the intermediate tensors on the fly via batches, say we do batch 1, then batch 2, we can reduce VRAM usage from 4GB to 2GB!\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dL}{dX} &= \\begin{bmatrix} \\frac{dL_1}{dy_1} W^T \\\\ \\frac{dL_2}{dy_2} W^T \\end{bmatrix} \\\\\n",
    "\\frac{dL}{dW} &= \\bigg( X_1^T \\frac{dL_1}{dy_1} + X_2^T  \\frac{dL_2}{dy_2} \\bigg)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. Your goal is to write a `torch.autograd.Function` with a `forward` and `backward` pass showcasing this memory efficient implementation.\n",
    "\n",
    "2. You must NOT hard code the derivatives - move the transformation function from the logits / intermeditate tensors to a smaller tensor as a separate function which can allow `autograd` to pass through it.\n",
    "\n",
    "3. As a hint, look at `torch.checkpoint` at https://github.com/pytorch/pytorch/blob/main/torch/utils/checkpoint.py. Also, don't forget about the upstream gradients! We need to multiply them to the current gradients!\n",
    "\n",
    "4. Make the Cross Entropy Loss work. You must show other functions working as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7458e",
   "metadata": {
    "papermill": {
     "duration": 0.002872,
     "end_time": "2025-03-17T11:12:50.872384",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.869512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576d582",
   "metadata": {
    "papermill": {
     "duration": 0.002836,
     "end_time": "2025-03-17T11:12:50.878236",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.875400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Marking Criteria for E) Max points = 10\n",
    "```python\n",
    "if attemped_E:\n",
    "    E_score = 0\n",
    "    if VRAM_50_percent_reduction: E_score += 2\n",
    "    if remove_float32_upcast: E_score = 0\n",
    "    if show_ce_loss_works: E_score += 1\n",
    "    if show_other_functions_work: E_score += 1\n",
    "    if hardcoded_gradients: E_score = 0\n",
    "    if allows_dynamic_chunk_sizes: E_score += 1\n",
    "    if llama_1B_training_loss_matches: E_score += 1\n",
    "    else: E_score = 0\n",
    "    if GRPO_memory_efficient_linear_works: E_score += 4\n",
    "    final_score += E_score\n",
    "else:\n",
    "    final_score += 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5df47",
   "metadata": {
    "papermill": {
     "duration": 0.002819,
     "end_time": "2025-03-17T11:12:50.884148",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.881329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "lets start by loading up the libraries necessary for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a2eb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:50.892869Z",
     "iopub.status.busy": "2025-03-17T11:12:50.892542Z",
     "iopub.status.idle": "2025-03-17T11:12:55.460709Z",
     "shell.execute_reply": "2025-03-17T11:12:55.459671Z"
    },
    "papermill": {
     "duration": 4.574087,
     "end_time": "2025-03-17T11:12:55.462601",
     "exception": false,
     "start_time": "2025-03-17T11:12:50.888514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e1571",
   "metadata": {
    "papermill": {
     "duration": 0.003132,
     "end_time": "2025-03-17T11:12:55.469349",
     "exception": false,
     "start_time": "2025-03-17T11:12:55.466217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "all you need is torch !!!! and you are good to goooo......  :) :0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198add71",
   "metadata": {
    "papermill": {
     "duration": 0.002986,
     "end_time": "2025-03-17T11:12:55.475508",
     "exception": false,
     "start_time": "2025-03-17T11:12:55.472522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "importing libraries in code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507f5ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:55.482914Z",
     "iopub.status.busy": "2025-03-17T11:12:55.482612Z",
     "iopub.status.idle": "2025-03-17T11:12:58.885632Z",
     "shell.execute_reply": "2025-03-17T11:12:58.884945Z"
    },
    "papermill": {
     "duration": 3.408519,
     "end_time": "2025-03-17T11:12:58.887251",
     "exception": false,
     "start_time": "2025-03-17T11:12:55.478732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d6426",
   "metadata": {
    "papermill": {
     "duration": 0.003527,
     "end_time": "2025-03-17T11:12:58.894543",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.891016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "writing the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10be986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:58.902138Z",
     "iopub.status.busy": "2025-03-17T11:12:58.901790Z",
     "iopub.status.idle": "2025-03-17T11:12:58.907957Z",
     "shell.execute_reply": "2025-03-17T11:12:58.906871Z"
    },
    "papermill": {
     "duration": 0.011338,
     "end_time": "2025-03-17T11:12:58.909234",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.897896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Transformation Functions ###\n",
    "\n",
    "def transformation_function_CE(batch, weight, labels):\n",
    "    \"\"\"\n",
    "    Compute cross entropy loss in sum-reduction mode without FP32 upcast.\n",
    "    Expects:\n",
    "      - batch: (B, S, D)\n",
    "      - weight: (vocab, D)\n",
    "      - labels: (B, S) or (B*S,) for CE loss.\n",
    "    \"\"\"\n",
    "    x = F.linear(batch, weight)  # no upcast; computed in bfloat16\n",
    "    loss_fct = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    loss = loss_fct(x.view(-1, x.size(-1)), labels.view(-1))\n",
    "    return loss\n",
    "\n",
    "def transformation_function_focal(batch, weight, labels, gamma=1.0, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Compute focal loss in sum-reduction mode.\n",
    "    Expects:\n",
    "      - batch: (B, S, D)\n",
    "      - weight: (vocab, D)\n",
    "      - labels: (B, S) or (B*S,) for classification.\n",
    "    \"\"\"\n",
    "    x = F.linear(batch, weight)\n",
    "    log_p = F.log_softmax(x, dim=-1)\n",
    "    p = log_p.exp()\n",
    "    target = labels.view(-1).long()\n",
    "    p_t = p.view(-1, x.size(-1)).gather(1, target.unsqueeze(1)) + eps\n",
    "    focal_factor = (1 - p_t) ** gamma\n",
    "    loss = - (focal_factor * log_p.view(-1, x.size(-1)).gather(1, target.unsqueeze(1))).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738f188",
   "metadata": {
    "papermill": {
     "duration": 0.003073,
     "end_time": "2025-03-17T11:12:58.915568",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.912495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "basic backprop initilisation + refrecing the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e29760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:58.922711Z",
     "iopub.status.busy": "2025-03-17T11:12:58.922496Z",
     "iopub.status.idle": "2025-03-17T11:12:58.935067Z",
     "shell.execute_reply": "2025-03-17T11:12:58.934473Z"
    },
    "papermill": {
     "duration": 0.017606,
     "end_time": "2025-03-17T11:12:58.936358",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.918752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Memory-Efficient Linear Function ###\n",
    "\n",
    "class MemoryEfficientLinear(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, X, weight, labels, forward_function, batch_chunk_size, seq_chunk_size):\n",
    "        \"\"\"\n",
    "        X: (B, S, D)\n",
    "        weight: (vocab, D)\n",
    "        labels: for CE and focal: (B*S,) (will be reshaped to (B,S))\n",
    "        forward_function: function to compute loss for a chunk.\n",
    "        batch_chunk_size: number of examples (B) per chunk.\n",
    "        seq_chunk_size: number of tokens (S) per chunk.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(X, weight, labels)\n",
    "        ctx.batch_chunk_size = batch_chunk_size\n",
    "        ctx.seq_chunk_size = seq_chunk_size\n",
    "        ctx.forward_function = forward_function\n",
    "\n",
    "        B, S, _ = X.shape\n",
    "        \n",
    "        # For CE, labels is 1D; for focal, also 1D.\n",
    "        if labels.dim() == 1:\n",
    "            labels_reshaped = labels.view(B, S)\n",
    "        elif labels.dim() == 3:\n",
    "            labels_reshaped = labels\n",
    "        else:\n",
    "            raise ValueError(\"Labels must be 1D or 3D.\")\n",
    "\n",
    "        # Accumulate loss in FP32 for better numerical precision.\n",
    "        total_loss = torch.tensor(0.0, dtype=torch.float32, device=X.device)\n",
    "        total_tokens = 0\n",
    "        for i in range(0, B, batch_chunk_size):\n",
    "            X_batch = X[i:i+batch_chunk_size]\n",
    "            labels_batch = labels_reshaped[i:i+batch_chunk_size]\n",
    "            for j in range(0, S, seq_chunk_size):\n",
    "                X_chunk = X_batch[:, j:j+seq_chunk_size]\n",
    "                if labels_reshaped.dim() == 2:\n",
    "                    labels_chunk = labels_batch[:, j:j+seq_chunk_size]\n",
    "                else:\n",
    "                    labels_chunk = labels_batch[:, j:j+seq_chunk_size, :]\n",
    "                chunk_loss = forward_function(X_chunk, weight, labels_chunk)\n",
    "                total_loss += chunk_loss.float()\n",
    "                total_tokens += X_chunk.size(0) * X_chunk.size(1)\n",
    "        ctx.total_tokens = total_tokens\n",
    "        final_loss = total_loss / total_tokens if total_tokens != 0 else torch.tensor(0.0, device=X.device)\n",
    "        # Return in the same dtype as X (bfloat16)\n",
    "        return final_loss.to(X.dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, d_loss):\n",
    "        X, W, labels = ctx.saved_tensors\n",
    "        batch_chunk_size = ctx.batch_chunk_size\n",
    "        seq_chunk_size = ctx.seq_chunk_size\n",
    "        forward_function = ctx.forward_function\n",
    "        total_tokens = ctx.total_tokens\n",
    "        B, S, _ = X.shape\n",
    "\n",
    "        d_X = torch.zeros_like(X) if X.requires_grad else None\n",
    "        d_W = torch.zeros_like(W) if W.requires_grad else None\n",
    "\n",
    "        if labels.dim() == 1:\n",
    "            labels_reshaped = labels.view(B, S)\n",
    "        elif labels.dim() == 3:\n",
    "            labels_reshaped = labels\n",
    "        else:\n",
    "            raise ValueError(\"Labels must be 1D or 3D.\")\n",
    "\n",
    "        for i in range(0, B, batch_chunk_size):\n",
    "            X_batch = X[i:i+batch_chunk_size]\n",
    "            labels_batch = labels_reshaped[i:i+batch_chunk_size]\n",
    "            for j in range(0, S, seq_chunk_size):\n",
    "                X_chunk = X_batch[:, j:j+seq_chunk_size].detach().requires_grad_(True)\n",
    "                labels_chunk = labels_batch[:, j:j+seq_chunk_size]\n",
    "                with torch.enable_grad():\n",
    "                    chunk_loss = forward_function(X_chunk, W, labels_chunk)\n",
    "                    # Use the same uniform scaling as in forward: divide by total_tokens.\n",
    "                    local_loss = chunk_loss / total_tokens\n",
    "                    gX, gW = torch.autograd.grad(local_loss, (X_chunk, W), retain_graph=True)\n",
    "                if d_X is not None:\n",
    "                    d_X[i:i+batch_chunk_size, j:j+seq_chunk_size] += gX * d_loss\n",
    "                if d_W is not None:\n",
    "                    d_W += gW * d_loss\n",
    "        return d_X, d_W, None, None, None, None\n",
    "\n",
    "### Reference Loss Functions ###\n",
    "\n",
    "def reference_loss_fn_CE(X, W, labels):\n",
    "    logits = F.linear(X, W)\n",
    "    B, S, _ = X.shape\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), reduction=\"sum\")\n",
    "    return loss / (B * S)\n",
    "\n",
    "def reference_loss_fn_focal(X, W, labels, gamma=1.0, eps=1e-7):\n",
    "    logits = F.linear(X, W)\n",
    "    log_p = F.log_softmax(logits, dim=-1)\n",
    "    p = log_p.exp()\n",
    "    target = labels.view(-1).long()\n",
    "    p_t = p.view(-1, logits.size(-1)).gather(1, target.unsqueeze(1)) + eps\n",
    "    focal_factor = (1 - p_t) ** gamma\n",
    "    loss = - (focal_factor * log_p.view(-1, logits.size(-1)).gather(1, target.unsqueeze(1))).sum()\n",
    "    B, S, _ = X.shape\n",
    "    return loss / (B * S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465a656",
   "metadata": {
    "papermill": {
     "duration": 0.003061,
     "end_time": "2025-03-17T11:12:58.942790",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.939729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "validating LLAMA 1B loss matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8ae490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:58.949788Z",
     "iopub.status.busy": "2025-03-17T11:12:58.949556Z",
     "iopub.status.idle": "2025-03-17T11:12:58.954714Z",
     "shell.execute_reply": "2025-03-17T11:12:58.954105Z"
    },
    "papermill": {
     "duration": 0.009945,
     "end_time": "2025-03-17T11:12:58.955886",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.945941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Llama-1B Training Loss Validation ###\n",
    "\n",
    "def validate_llama_training_loss_matches():\n",
    "    \"\"\"\n",
    "    Validate that the memory-efficient linear function produces a training loss\n",
    "    that matches the full (reference) computation under Llama-1B parameters.\n",
    "    \"\"\"\n",
    "    bsz, qlen, hd, vocab = 4, 4096, 4096, 128000  # Llama-1B parameters\n",
    "    X_large = torch.randn(bsz, qlen, hd, dtype=torch.bfloat16, device=device, requires_grad=True)\n",
    "    W_large = torch.randn(vocab, hd, dtype=torch.bfloat16, device=device, requires_grad=True)\n",
    "    labels_large = torch.randint(0, vocab, (bsz * qlen,), device=device)\n",
    "    \n",
    "    # Compute reference loss with sum reduction divided by (B*S)\n",
    "    loss_ref = F.cross_entropy(F.linear(X_large, W_large).view(-1, vocab),\n",
    "                               labels_large.view(-1),\n",
    "                               reduction=\"sum\") / (bsz * qlen)\n",
    "    \n",
    "    # Compute memory-efficient loss.\n",
    "    loss_mem = MemoryEfficientLinear.apply(X_large, W_large, labels_large, transformation_function_CE, 1, 1024)\n",
    "    \n",
    "    print(\"Llama-1B Reference Loss: {:.4f}\".format(loss_ref.item()))\n",
    "    print(\"Llama-1B Memory-Efficient Loss: {:.4f}\".format(loss_mem.item()))\n",
    "    if torch.allclose(torch.tensor(loss_ref.item()), torch.tensor(loss_mem.item()), atol=1e-3):\n",
    "        print(\"Llama-1B training loss matches!\")\n",
    "    else:\n",
    "        print(\"Llama-1B training loss does NOT match.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59c890",
   "metadata": {
    "papermill": {
     "duration": 0.002982,
     "end_time": "2025-03-17T11:12:58.962143",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.959161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "GPRO functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0ed355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:58.969304Z",
     "iopub.status.busy": "2025-03-17T11:12:58.969052Z",
     "iopub.status.idle": "2025-03-17T11:12:58.975710Z",
     "shell.execute_reply": "2025-03-17T11:12:58.974891Z"
    },
    "papermill": {
     "duration": 0.011502,
     "end_time": "2025-03-17T11:12:58.976865",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.965363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Validation Routine for Other Functions ###\n",
    "\n",
    "def validate_GRPO_memory_efficient_linear(loss_fn, transformation_fn, label_dim, loss_name=\"\"):\n",
    "    bsz, qlen, hd, vocab = 2, 1024, 512, 10000\n",
    "    X_val = torch.randn(bsz, qlen, hd, dtype=torch.bfloat16, device=device, requires_grad=True)\n",
    "    W_val = torch.randn(vocab, hd, dtype=torch.bfloat16, device=device, requires_grad=True)\n",
    "    if label_dim == 2:\n",
    "        labels_val = torch.randint(0, vocab, (bsz * qlen,), device=device)\n",
    "    elif label_dim == 3:\n",
    "        labels_val = torch.randn(bsz, qlen, vocab, dtype=torch.bfloat16, device=device)\n",
    "    else:\n",
    "        raise ValueError(\"label_dim must be 2 or 3.\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    loss_ref = loss_fn(X_val, W_val, labels_val)\n",
    "    loss_ref.backward()\n",
    "    ref_peak = torch.cuda.max_memory_allocated(device)\n",
    "    ref_dX = X_val.grad.clone()\n",
    "    ref_dW = W_val.grad.clone()\n",
    "\n",
    "    X_val.grad.zero_()\n",
    "    W_val.grad.zero_()\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    loss_chunked = MemoryEfficientLinear.apply(X_val, W_val, labels_val, transformation_fn, 1, 256)\n",
    "    loss_chunked.backward()\n",
    "    chunk_peak = torch.cuda.max_memory_allocated(device)\n",
    "    reduction = (ref_peak - chunk_peak) / ref_peak * 100 if ref_peak != 0 else 0\n",
    "\n",
    "    print(f\"{loss_name} Reference Loss: {loss_ref.item():.4f}\")\n",
    "    print(f\"{loss_name} Chunked Loss:   {loss_chunked.item():.4f}\")\n",
    "    print(\"X gradients match? \", torch.allclose(X_val.grad, ref_dX, atol=1e-3))\n",
    "    print(\"W gradients match? \", torch.allclose(W_val.grad, ref_dW, atol=1e-3))\n",
    "    print(\"Reference peak memory (bytes):\", ref_peak)\n",
    "    print(\"Chunked peak memory (bytes):  \", chunk_peak)\n",
    "    print(f\"Percent VRAM reduction: {reduction:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878053e",
   "metadata": {
    "papermill": {
     "duration": 0.002984,
     "end_time": "2025-03-17T11:12:58.983131",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.980147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A call to the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9036476f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T11:12:58.990275Z",
     "iopub.status.busy": "2025-03-17T11:12:58.989976Z",
     "iopub.status.idle": "2025-03-17T11:13:38.232041Z",
     "shell.execute_reply": "2025-03-17T11:13:38.231128Z"
    },
    "papermill": {
     "duration": 39.250437,
     "end_time": "2025-03-17T11:13:38.236665",
     "exception": false,
     "start_time": "2025-03-17T11:12:58.986228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Test Loss: 284.0\n",
      "Gradients for X computed: True\n",
      "Gradients for W computed: True\n",
      "\n",
      "Validating Cross Entropy (CE) version:\n",
      "CE Reference Loss: 87.5000\n",
      "CE Chunked Loss:   87.5000\n",
      "X gradients match?  True\n",
      "W gradients match?  True\n",
      "Reference peak memory (bytes): 2517992960\n",
      "Chunked peak memory (bytes):   2463371264\n",
      "Percent VRAM reduction: 2.17%\n",
      "\n",
      "Validating Focal (other function) version:\n",
      "Focal Reference Loss: 87.5000\n",
      "Focal Chunked Loss:   87.5000\n",
      "X gradients match?  True\n",
      "W gradients match?  True\n",
      "Reference peak memory (bytes): 2599912960\n",
      "Chunked peak memory (bytes):   2469417984\n",
      "Percent VRAM reduction: 5.02%\n",
      "\n",
      "Validating Llama-1B Training Loss Matching:\n",
      "Llama-1B Reference Loss: 284.0000\n",
      "Llama-1B Memory-Efficient Loss: 284.0000\n",
      "Llama-1B training loss matches!\n"
     ]
    }
   ],
   "source": [
    "### Main Testing ###\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Full test for CE.\n",
    "    bsz, qlen, hd, vocab = 4, 4096, 4096, 128000\n",
    "    X = torch.randn(bsz, qlen, hd, dtype=torch.bfloat16, device=device, requires_grad=True)\n",
    "    W = torch.randn(vocab, hd, dtype=torch.bfloat16, device=device, requires_grad=True)\n",
    "    labels_CE = torch.randint(0, vocab, (bsz * qlen,), device=device)\n",
    "    loss_CE = MemoryEfficientLinear.apply(X, W, labels_CE, transformation_function_CE, 1, 1024)\n",
    "    loss_CE.backward()\n",
    "    print(\"CE Test Loss:\", loss_CE.item())\n",
    "    print(\"Gradients for X computed:\", X.grad is not None)\n",
    "    print(\"Gradients for W computed:\", W.grad is not None)\n",
    "    print()\n",
    "\n",
    "    print(\"Validating Cross Entropy (CE) version:\")\n",
    "    validate_GRPO_memory_efficient_linear(reference_loss_fn_CE, transformation_function_CE, label_dim=2, loss_name=\"CE\")\n",
    "\n",
    "    print(\"Validating Focal (other function) version:\")\n",
    "    validate_GRPO_memory_efficient_linear(lambda X,W,labels: reference_loss_fn_focal(X,W,labels, gamma=1.0, eps=1e-7),\n",
    "                                            lambda b,w,l: transformation_function_focal(b,w,l, gamma=1.0, eps=1e-7),\n",
    "                                            label_dim=2,\n",
    "                                            loss_name=\"Focal\")\n",
    "    \n",
    "    print(\"Validating Llama-1B Training Loss Matching:\")\n",
    "    validate_llama_training_loss_matches()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 51.454247,
   "end_time": "2025-03-17T11:13:39.461278",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-17T11:12:48.007031",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
